{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Colab y PySpark - Inicio.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"oVVqay4q7ZnA","colab_type":"text"},"source":["#**Introduccion a Big Data**\n","##Jugando con Colab & Spark  (Python)\n","\n","De forma bastante practico para utilizar  pyspark en Colab seria ejecutar algunos de los siguientes comandos en una celda en Colab:\n","\n","Haremos lo siguiente :\n","\n","*   Instalacion Rapida Java y Spark\n","*   Configuracion Veloz de Java y Spark\n","*   Ejemplos utilizando PySpark\n"]},{"cell_type":"markdown","metadata":{"id":"k89QGd7J7VwQ","colab_type":"text"},"source":["##Instalar Java y Spark\n","Podemos hacer rapidamente que nuestro entorno de ejecucion implemente Java"]},{"cell_type":"code","metadata":{"id":"t42JVLhu7RwK","colab_type":"code","colab":{}},"source":["!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2iDa-IbF9gzi","colab_type":"text"},"source":["Vamos a la direccion web de Apache Spark, obtenemos la version deseada y la desempaquetamos"]},{"cell_type":"code","metadata":{"id":"06CCMa0z9Xag","colab_type":"code","colab":{}},"source":["import os # libreria de manejo del sistema operativo\n","os.system(\"wget -q https://www-us.apache.org/dist/spark/spark-2.4.5/spark-2.4.5-bin-hadoop2.7.tgz\")\n","os.system(\"tar -xzvf spark-2.4.5-bin-hadoop2.7.tgz\")\n","!ls ##listamos los archivos"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"R50XO2tc93zU","colab_type":"text"},"source":["Ahora instalamos **pyspark**"]},{"cell_type":"code","metadata":{"id":"3fm3xpqn96zo","colab_type":"code","colab":{}},"source":["!pip install -q pyspark\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Arr81wzs9__C","colab_type":"text"},"source":["##Configuramos las variables de Java y Spark\n"]},{"cell_type":"code","metadata":{"id":"bep7dZV6-8Po","colab_type":"code","colab":{}},"source":["!rm spark-2.4.5-bin-hadoop2.7.tgz.1\n","!rm spark-2.4.5-bin-hadoop2.7.tgz.2\n","!ls /content/"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"7q65rYcm-GPz","colab_type":"code","colab":{}},"source":["# Variables de Entorno\n","os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n","os.environ[\"SPARK_HOME\"] = f\"/content/spark-2.4.5-bin-hadoop2.7\""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZOfr75Rr-g9b","colab_type":"text"},"source":["#Iniciamos y Utilizamos PySpark\n","\n","Iniciamos con la importacion de lirerias necesarias y la creacion de una sesion de Spark"]},{"cell_type":"code","metadata":{"id":"oWvuNcwz-jWj","colab_type":"code","colab":{}},"source":["# Cargar Pyspark\n","from pyspark.sql import SparkSession\n","spark = SparkSession.builder.appName(\"Test_spark\").master(\"local[*]\").getOrCreate()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"n0nW5DOyRuqg","colab_type":"text"},"source":["Imprimimos los valores de la sesion"]},{"cell_type":"code","metadata":{"id":"wZXIpIY4RjUm","colab_type":"code","colab":{}},"source":["spark"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uiSRvhjFSCZH","colab_type":"text"},"source":["En la carpeta sample_dara Colab nos ofrece algunos datasets de muestra, damos una mirada rapida al archivo **./sample_data/california_housing_train.csv**\n"]},{"cell_type":"code","metadata":{"id":"l2L1GT3ESTUy","colab_type":"code","colab":{}},"source":["!head -n 10 ./sample_data/california_housing_train.csv"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"gg0560KuR_p-","colab_type":"code","colab":{}},"source":["#Cargamos el ARchivo con Spark (en Memoria)\n","archivo = './sample_data/california_housing_train.csv'\n","df_spark = spark.read.csv(archivo, inferSchema=True, header=True)\n","\n","# imprimir tipo de archivo\n","print(type(df_spark))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9tSNyK81S5Bu","colab_type":"text"},"source":["###¿Cuantos registros posee este dataframe?"]},{"cell_type":"code","metadata":{"id":"9Oizz5AMS9KV","colab_type":"code","colab":{}},"source":["df_spark.count()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cx7BQH-jTCjT","colab_type":"text"},"source":["### ¿Cual es la estructura del Dataframe?\n"]},{"cell_type":"code","metadata":{"id":"mZw-WwK9TFSp","colab_type":"code","colab":{}},"source":["df_spark.printSchema()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fHesamtOTNei","colab_type":"text"},"source":["###¿Cual es el nombre de las columnas?\n"]},{"cell_type":"code","metadata":{"id":"nPhAnSEDTQew","colab_type":"code","colab":{}},"source":["df_spark.columns"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"iyp9rWi7TVgO","colab_type":"text"},"source":["###Mostrar los primeros Registros"]},{"cell_type":"code","metadata":{"id":"EUQsj9BFTYrF","colab_type":"code","colab":{}},"source":["#Ver los primeros 20 registros del dataframe\n","df_spark.show()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"U9UvaplITlQy","colab_type":"text"},"source":["###Hagamos una Descricipcion Estadistica del dataframe"]},{"cell_type":"code","metadata":{"id":"uSxkd9UPTjlR","colab_type":"code","colab":{}},"source":["df_spark.describe().toPandas().transpose()\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"3eeW1eIaW8SB","colab_type":"code","colab":{}},"source":["df_spark.describe().show()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"WK49QBRGUM_K","colab_type":"code","colab":{}},"source":["df_spark.describe(['median_house_value']).show()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YEqzYPLAWdy3","colab_type":"text"},"source":["###Generacion de Datos Aleatorios\n","La generación de datos aleatorios es útil para probar algoritmos existentes e implementar algoritmos aleatorios, como la proyección aleatoria. **Spark** proporciona métodos para generar columnas que contienen valores extraídos de una distribución, por ejemplo, uniforme (rand) y normal estándar (randn)."]},{"cell_type":"code","metadata":{"id":"yp7sLZk4V6lG","colab_type":"code","colab":{}},"source":["df = spark.range(0, 10)\n","df.show()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"vacC0IraWIZx","colab_type":"code","colab":{}},"source":["from pyspark.sql.functions import rand, randn\n","\n","df.select(\"id\", rand(seed=10).alias(\"uniform\"), randn(seed=27).alias(\"normal\")).show()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OZZczhLFUUXD","colab_type":"text"},"source":["De esta forma se puede instalar automaticamente spark en google colab y hacer uno de el de forma gratis.\n","\n","En la version gratis solo se cuenta con una CPU si se quiere aumentar la capacidad de procesamiento es necesario pagar."]}]}